#!/usr/bin/env python3
"""
Evolved solver for Synergistic Dependency Selection (SDS) problem.
This EVOLVE-BLOCK contains an improved parametric local-search algorithm.
"""

import json
import sys
import contextlib
import math
import random
import time
from collections import defaultdict, deque

# EVOLVE-BLOCK-START
def solve_sds():
    """
    Solve the Synergistic Dependency Selection problem using:
    - precedence closure-aware greedy initialization
    - adaptive interaction weighting
    - local search (add/remove/swap) with occasional random shake
    """
    # Read input
    input_data = json.load(sys.stdin)
    requirements = input_data.get("requirements", {})
    catalog = input_data.get("catalog", {})
    
    weights = requirements.get("weights", [])
    interactions_raw = requirements.get("interactions", {})
    cardinality_bounds = requirements.get("cardinality_bounds", [0, len(weights)])
    mutex_list = requirements.get("mutex", [])
    groups = requirements.get("groups", {})
    precedence = requirements.get("precedence", [])
    
    n = len(weights)
    
    # Parse interactions into dict of tuple(int,int)->float, symmetric
    interactions = {}
    total_abs_inter = 0.0
    inter_count = 0
    for k, v in interactions_raw.items():
        try:
            # accept "i,j" with optional spaces
            parts = k.split(",")
            if len(parts) != 2:
                continue
            u = int(parts[0].strip())
            w = int(parts[1].strip())
            if u == w:
                # ignore self interactions
                continue
            interactions[(u, w)] = float(v)
            interactions[(w, u)] = float(v)
            total_abs_inter += abs(float(v))
            inter_count += 1
        except Exception:
            continue
    avg_abs_inter = (total_abs_inter / inter_count) if inter_count > 0 else 0.0
    avg_abs_weight = (sum(abs(float(x)) for x in weights) / n) if n > 0 else 0.0
    
    # Adaptive interaction bias: scale interactions to be comparable to weights
    interaction_bias = 1.0
    if avg_abs_weight > 1e-9:
        interaction_bias = max(0.2, min(3.0, (avg_abs_inter / (avg_abs_weight + 1e-9)) * 1.2))
    # parameters (tunable)
    MAX_ITERS = 5000
    NO_IMPROVE_PATIENCE = 200
    TOP_K_CANDIDATES = 50  # when searching adds/swaps consider top candidates by heuristic
    SHAKE_PROB = 0.02
    INIT_TEMP = 0.5
    COOLING = 0.995
    
    # Build precedence graph: j -> list of required preds i (if j selected, i must be selected)
    preds = defaultdict(set)
    succs = defaultdict(set)  # reverse: i -> set of nodes that require i
    for pair in precedence:
        try:
            a, b = pair
            preds[int(b)].add(int(a))
            succs[int(a)].add(int(b))
        except Exception:
            continue
    
    # Build group mapping: group_id -> set(vars), and var->set(group_ids)
    group_to_vars = {}
    var_to_groups = defaultdict(set)
    for gid, vars_list in groups.items():
        # group ids may be strings; treat as keys
        try:
            vars_iter = list(vars_list)
        except Exception:
            vars_iter = []
        group_to_vars[gid] = set(vars_iter)
        for v in vars_iter:
            var_to_groups[int(v)].add(gid)
    
    # Build mutex set for quick lookup (unordered pair)
    mutex_set = set()
    for pair in mutex_list:
        if len(pair) >= 2:
            a, b = int(pair[0]), int(pair[1])
            if a == b:
                continue
            mutex_set.add((a, b))
            mutex_set.add((b, a))
    
    # Helper: get full precedence closure for a set of variables (all ancestors)
    def closure_of_set(vars_set):
        # BFS/DFS up preds edges
        res = set(vars_set)
        dq = deque(vars_set)
        while dq:
            v = dq.popleft()
            for p in preds.get(v, ()):
                if p not in res:
                    res.add(p)
                    dq.append(p)
        return res
    
    # Helper: compute dependents closure (all nodes that require any in given set) - for removal cascades
    def dependents_to_remove_for_removed(removed_vars, current_selected):
        # If we remove some vars, any node that (directly or transitively) requires them must also be removed
        to_remove = set()
        dq = deque()
        for r in removed_vars:
            # only consider dependents that are currently selected
            for s in succs.get(r, ()):
                if s in current_selected and s not in to_remove:
                    to_remove.add(s)
                    dq.append(s)
        while dq:
            v = dq.popleft()
            for s in succs.get(v, ()):
                if s in current_selected and s not in to_remove:
                    to_remove.add(s)
                    dq.append(s)
        return to_remove
    
    # Objective evaluation
    def objective(selected_set):
        # sum weights + sum pairwise interactions (each counted once)
        s = 0.0
        for v in selected_set:
            if 0 <= v < n:
                s += float(weights[v])
        # interactions: iterate pairs from interactions dict unique by u<v
        # More efficient: for each u in selected, sum interactions[u,w] for w>u in selected
        sel_list = list(selected_set)
        sel_set = set(selected_set)
        # sum interactions symmetrically but ensure we add each pair once
        seen = set()
        for u in sel_list:
            for v in sel_list:
                if u == v:
                    continue
                if (u, v) in seen:
                    continue
                val = interactions.get((u, v), 0.0)
                if val != 0.0:
                    s += val * 1.0  # interactions already raw; bias applied when used for heuristics
                seen.add((u, v))
                seen.add((v, u))
        return s
    
    # Feasibility checks
    def violates_mutex_pairing(candidate_set):
        # simple O(k^2) check for small sets
        for a in candidate_set:
            for b in candidate_set:
                if a != b and (a, b) in mutex_set:
                    return True
        return False
    
    def violates_grouping(candidate_set):
        # at most one per group id
        group_seen = {}
        for v in candidate_set:
            for gid in var_to_groups.get(v, ()):
                if gid in group_seen and group_seen[gid] != v:
                    return True
                group_seen[gid] = v
        return False
    
    def feasible_after_adding(i, current_set, max_card):
        # compute closure for i
        to_add_closure = closure_of_set({i})
        # new_set = current_set U to_add_closure
        new_set = set(current_set) | to_add_closure
        # Check cardinality
        if len(new_set) > max_card:
            return False, None
        # Check group and mutex
        if violates_grouping(new_set):
            return False, None
        if violates_mutex_pairing(new_set):
            return False, None
        return True, to_add_closure
    
    def feasible_swap(remove_set, add_set, current_set, min_card, max_card):
        # remove_set: set of vars to remove (e.g. {a} plus dependents)
        # add_set: set of vars to add (including closures)
        new_set = set(current_set)
        # cascade removals of dependents
        removed_final = set(remove_set) | dependents_to_remove_for_removed(remove_set, current_set)
        new_set -= removed_final
        new_set |= add_set
        # add closure for add_set (in case not already included)
        new_set |= closure_of_set(add_set)
        # Check cardinality
        if len(new_set) < min_card or len(new_set) > max_card:
            return False, None
        if violates_grouping(new_set):
            return False, None
        if violates_mutex_pairing(new_set):
            return False, None
        return True, new_set
    
    # Greedy initialization (precedence-aware)
    min_card, max_card = int(cardinality_bounds[0]), int(cardinality_bounds[1])
    selected = set()
    
    # Candidate heuristic score: marginal weight + interaction_bias * sum interactions to current selected +
    # include closure contributions (weights + interactions inside closure)
    def marginal_gain_if_add(i, current_set):
        feasible, closure = feasible_after_adding(i, current_set, max_card)
        if not feasible:
            return -math.inf, None
        closure = closure or set()
        new_items = closure - current_set
        # compute sum weights for new items
        gain = 0.0
        for v in new_items:
            if 0 <= v < n:
                gain += float(weights[v])
        # interactions: between new items and existing items, and between new items themselves
        for u in new_items:
            # interactions with current_set
            for v in current_set:
                gain += interaction_bias * interactions.get((u, v), 0.0)
            # interactions inside new_items (u <-> w)
            for w in new_items:
                if u >= w:
                    continue
                gain += interaction_bias * interactions.get((u, w), 0.0)
        # also subtract any negative interactions that new items might have with existing set (already accounted)
        return gain, closure
    
    # Seed selection: choose highest marginal gains until max or no positive gains; also aim to reach min_card
    # We'll consider candidates sorted by heuristic that includes interactions to the yet-empty set (so primarily weights)
    candidate_scores = []
    for i in range(n):
        # simple base heuristic: weight + interaction_bias * sum of abs interactions to others (potential)
        pot = float(weights[i]) + interaction_bias * sum(interactions.get((i, j), 0.0) for j in range(n) if j != i)
        candidate_scores.append((pot, i))
    candidate_scores.sort(reverse=True)
    for _, i in candidate_scores:
        if len(selected) >= max_card:
            break
        mg, closure = marginal_gain_if_add(i, selected)
        if closure is None:
            continue
        # prefer positive gain or needed to reach min_card
        if mg > -1e-9 or len(selected) + len(closure - selected) <= min_card:
            selected |= closure
    # If still below min_card, add best feasible items forcibly (minimal harm)
    if len(selected) < min_card:
        for i in range(n):
            if len(selected) >= min_card:
                break
            feasible, closure = feasible_after_adding(i, selected, max_card)
            if not feasible:
                continue
            selected |= closure
    # If above max_card due to closure, attempt to prune (rare): remove least valuable items that have no dependents
    def prune_to_max(selected_set):
        if len(selected_set) <= max_card:
            return selected_set
        # remove candidates with smallest marginal loss (removing them and their dependents)
        sel = set(selected_set)
        while len(sel) > max_card:
            best_loss = math.inf
            best_remove = None
            for v in list(sel):
                # cannot remove if it causes removing many required items might be large loss - we measure objective delta
                removed = {v} | dependents_to_remove_for_removed({v}, sel)
                new_set = sel - removed
                loss = objective(sel) - objective(new_set)
                if loss < best_loss:
                    best_loss = loss
                    best_remove = removed
            if best_remove is None:
                break
            sel -= best_remove
        return sel
    if len(selected) > max_card:
        selected = prune_to_max(selected)
    
    # Local search improvement
    current = set(selected)
    best = set(current)
    best_score = objective(best)
    current_score = best_score
    no_improve = 0
    temperature = INIT_TEMP
    rng = random.Random(123456789)  # deterministic seed for reproducibility
    
    iter_count = 0
    while iter_count < MAX_ITERS and no_improve < NO_IMPROVE_PATIENCE:
        iter_count += 1
        improved = False
        
        # Build candidate lists
        not_selected = [i for i in range(n) if i not in current]
        # Evaluate marginal gains for top candidates
        add_candidates = []
        for i in not_selected:
            mg, closure = marginal_gain_if_add(i, current)
            if closure is None:
                continue
            add_candidates.append((mg, i, closure))
        add_candidates.sort(reverse=True, key=lambda x: x[0])
        
        # Consider removals: compute marginal loss for removing each v (including dependents)
        remove_candidates = []
        for v in list(current):
            removed = {v} | dependents_to_remove_for_removed({v}, current)
            new_set = current - removed
            if len(new_set) < min_card:
                # can't remove below min
                continue
            loss = objective(current) - objective(new_set)
            remove_candidates.append((loss, v, removed))
        remove_candidates.sort(key=lambda x: x[0])  # smaller loss first
        
        # Try best add move
        if add_candidates:
            mg, i_add, closure_add = add_candidates[0]
            if mg > 1e-9 and len(current | closure_add) <= max_card:
                # apply add
                current |= closure_add
                current_score = objective(current)
                if current_score > best_score + 1e-9:
                    best = set(current)
                    best_score = current_score
                    no_improve = 0
                else:
                    no_improve += 1
                improved = True
            else:
                # Try beneficial swaps: remove some v and add some u
                # Consider top few adds and top few removes
                swapped = False
                top_adds = add_candidates[:TOP_K_CANDIDATES]
                top_removes = remove_candidates[:TOP_K_CANDIDATES]
                best_delta = 0.0
                best_move = None
                # Try single removals + single addition
                for mg_val, u, closure_u in top_adds:
                    for loss_val, v, removed_set in top_removes:
                        # prepare add_set = closure_u
                        feasible, new_set = feasible_swap(removed_set, closure_u, current, min_card, max_card)
                        if not feasible:
                            continue
                        new_score = objective(new_set)
                        delta = new_score - current_score
                        if delta > best_delta:
                            best_delta = delta
                            best_move = ("swap", removed_set, closure_u, new_set, new_score)
                if best_move:
                    # apply best swap
                    _, removed_set, closure_u, new_set, new_score = best_move
                    current = set(new_set)
                    current_score = new_score
                    if current_score > best_score + 1e-9:
                        best = set(current)
                        best_score = current_score
                        no_improve = 0
                    else:
                        no_improve += 1
                    improved = True
                    swapped = True
                else:
                    # consider accepting a small worsening move probabilistically (simulated annealing)
                    if add_candidates and remove_candidates:
                        # pick top random pair and consider
                        cand_add = rng.choice(add_candidates[:min(5, len(add_candidates))])
                        cand_rem = rng.choice(remove_candidates[:min(5, len(remove_candidates))])
                        _, u, closure_u = cand_add
                        _, v, removed_set = cand_rem
                        feasible, new_set = feasible_swap(removed_set, closure_u, current, min_card, max_card)
                        if feasible:
                            new_score = objective(new_set)
                            delta = new_score - current_score
                            if delta > 0 or rng.random() < math.exp(delta / (temperature + 1e-12)):
                                current = set(new_set)
                                current_score = new_score
                                if current_score > best_score + 1e-9:
                                    best = set(current)
                                    best_score = current_score
                                    no_improve = 0
                                else:
                                    no_improve += 1
                                improved = True
        # If not improved, try pure removal if it leads to improvement (prune negative items)
        if not improved and remove_candidates:
            # remove the item which gives largest improvement (largest 'negative loss' meaning reduce objective negative interactions)
            # We look for removals that increase objective (loss < 0)
            candidate_removals = [rc for rc in remove_candidates if rc[0] < -1e-9]
            if candidate_removals:
                candidate_removals.sort()
                loss_val, v, removed_set = candidate_removals[0]
                new_set = current - removed_set
                current = set(new_set)
                current_score = objective(current)
                if current_score > best_score + 1e-9:
                    best = set(current)
                    best_score = current_score
                    no_improve = 0
                else:
                    no_improve += 1
                improved = True
        
        # Random shake (small) to escape plateaus
        if not improved and rng.random() < SHAKE_PROB:
            # attempt random feasible add or swap
            if add_candidates:
                _, u, closure_u = rng.choice(add_candidates[:min(10, len(add_candidates))])
                feasible_add, closure = feasible_after_adding(u, current, max_card)
                if feasible_add:
                    current |= closure
                    current_score = objective(current)
                    if current_score > best_score + 1e-9:
                        best = set(current)
                        best_score = current_score
                        no_improve = 0
                    else:
                        no_improve += 1
                    improved = True
            elif remove_candidates:
                _, v, removed_set = rng.choice(remove_candidates[:min(10, len(remove_candidates))])
                new_set = current - removed_set
                if len(new_set) >= min_card:
                    current = set(new_set)
                    current_score = objective(current)
                    if current_score > best_score + 1e-9:
                        best = set(current)
                        best_score = current_score
                        no_improve = 0
                    else:
                        no_improve += 1
                    improved = True
        
        if not improved:
            no_improve += 1
        
        # cooling
        temperature *= COOLING
    
    # Final pruning to ensure within cardinality bounds and precedence closure
    final_sel = closure_of_set(best)
    # If still beyond max, prune low-contribution items
    if len(final_sel) > max_card:
        final_sel = prune_to_max(final_sel)
    # Ensure at least min_card
    if len(final_sel) < min_card:
        # greedily add best remaining feasible items
        for i in range(n):
            if len(final_sel) >= min_card:
                break
            feasible, closure = feasible_after_adding(i, final_sel, max_card)
            if feasible:
                final_sel |= closure
    final_list = sorted(int(x) for x in final_sel)
    result = {"selection": {"variables": final_list}}
    print(json.dumps(result))
# EVOLVE-BLOCK-END


# This part remains fixed (not evolved)
def run_sds(problem_data=None):
    """
    Main function called by the evaluator.
    Can accept problem_data as parameter or read from stdin.
    Returns JSON string (for ShinkaEvolve) or prints to stdout (for direct execution).
    """
    import sys
    import json
    import io
    
    if problem_data is None:
        # Read from stdin (for compatibility)
        input_data = json.load(sys.stdin)
    else:
        # Use provided problem data
        input_data = problem_data
    
    # Capture stdout from solve_sds
    stdout_capture = io.StringIO()
    old_stdin = sys.stdin
    
    try:
        # Create mock stdin
        sys.stdin = io.StringIO(json.dumps(input_data))
        with contextlib.redirect_stdout(stdout_capture):
            solve_sds()
    finally:
        sys.stdin = old_stdin
    
    result_str = stdout_capture.getvalue()
    return result_str


# If run as a script, call solve_sds()
if __name__ == "__main__":
    solve_sds()